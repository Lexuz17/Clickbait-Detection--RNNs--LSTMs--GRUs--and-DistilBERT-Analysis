{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asa9NxuBqpiO"
      },
      "source": [
        "# Transformer & Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i5pJPzBLGrc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vi8e2iayMq-z",
        "outputId": "93fa6563-4d1f-414f-b578-933360675adf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8fffb7e4-3417-44cc-a18f-e0b66d1acf42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>clickbait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Should I Get Bings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which TV Female Friend Group Do You Belong In</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The New \"Star Wars: The Force Awakens\" Trailer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This Vine Of New York On \"Celebrity Big Brothe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Couple Did A Stunning Photo Shoot With Their...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fffb7e4-3417-44cc-a18f-e0b66d1acf42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8fffb7e4-3417-44cc-a18f-e0b66d1acf42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8fffb7e4-3417-44cc-a18f-e0b66d1acf42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13a008ea-c2b0-4d9c-af3b-3701b5c888de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13a008ea-c2b0-4d9c-af3b-3701b5c888de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13a008ea-c2b0-4d9c-af3b-3701b5c888de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            headline  clickbait\n",
              "0                                 Should I Get Bings          1\n",
              "1      Which TV Female Friend Group Do You Belong In          1\n",
              "2  The New \"Star Wars: The Force Awakens\" Trailer...          1\n",
              "3  This Vine Of New York On \"Celebrity Big Brothe...          1\n",
              "4  A Couple Did A Stunning Photo Shoot With Their...          1"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"clickbait.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws9cQsKMXQbF",
        "outputId": "9cdcee4e-e4ac-42fd-d43b-6f4bb2ac90d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32000, 2)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXfLBHNJMvtw",
        "outputId": "591012d6-6dc2-4186-f2ce-b9b646954a77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    16001\n",
              "1    15999\n",
              "Name: clickbait, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['clickbait'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olmabgsVXctW",
        "outputId": "4be1eb29-71b1-422f-b756-a11bac567389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32000 entries, 0 to 31999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   headline   32000 non-null  object\n",
            " 1   clickbait  32000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 500.1+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFNpXkqJXlD5"
      },
      "source": [
        "Memeriksa jumlah maksimal kata yang dapat hadir dalam sebuah headline, ini akan membantu kita dalam proses padding nantinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg7qiKibXh0x",
        "outputId": "aa3d1bec-70c2-43f1-bc8e-cdfa7398fac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['headline'].apply(lambda x:len(str(x).split())).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pF-XsSVY01Y"
      },
      "source": [
        "## **DATA PREPARATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O5pDLVcc0g0"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence, text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdN0Bij1ZkOo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-oXgVuLY39M",
        "outputId": "1dcefbe1-0c2a-4595-f035-027210bde5c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X_train: (25600,)\n",
            "Shape y_train: (25600,)\n",
            "Shape X_val: (3200,)\n",
            "Shape y_val: (3200,)\n",
            "Shape X_test: (3200,)\n",
            "Shape y_test: (3200,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(df.headline, df.clickbait,\n",
        "                                                    stratify=df.clickbait.values,\n",
        "                                                    random_state = 42,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp,\n",
        "                                                stratify=y_temp.values,\n",
        "                                                random_state = 42,\n",
        "                                                test_size = 0.5,\n",
        "                                                shuffle=True)\n",
        "\n",
        "# Menampilkan shape dari setiap subset\n",
        "print(\"Shape X_train:\", X_train.shape)\n",
        "print(\"Shape y_train:\", y_train.shape)\n",
        "print(\"Shape X_val:\", X_val.shape)\n",
        "print(\"Shape y_val:\", y_val.shape)\n",
        "print(\"Shape X_test:\", X_test.shape)\n",
        "print(\"Shape y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7MT-2WRmNe5"
      },
      "source": [
        "**Tokenization** is the process of converting text into a sequence of numbers or tokens. In the context of its use in an RNN model, each word in a sentence is represented as a one-hot vector with a dimension equal to the number of words in the vocabulary + 1. The Keras Tokenizer is employed to create a dictionary of unique words in the corpus, sorting them based on their frequency of occurrence, and then assigning a numerical index to each word. This process results in numerical representations for each word in the sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDXl_e8JoWJe"
      },
      "source": [
        "**Padding** is the process of adding zero values to a sequence of words so that all sequences have the same length. This is useful because RNN models require inputs with uniform length. Padding is performed to make the lengths of all sequences the same, regardless of the original length of the sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J42doiVhcheY"
      },
      "outputs": [],
      "source": [
        "# Using Keras Tokenizer.\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 30\n",
        "\n",
        "# Fit the tokenizer on the training and validation data.\n",
        "token.fit_on_texts(list(X_train) + list(X_val))\n",
        "X_train_seq = token.texts_to_sequences(X_train)\n",
        "X_valid_seq = token.texts_to_sequences(X_val)\n",
        "X_test_seq = token.texts_to_sequences(X_test)\n",
        "\n",
        "# Zero pad the sequences to ensure uniform length.\n",
        "X_train_pad = sequence.pad_sequences(X_train_seq, maxlen=max_len, padding='pre')\n",
        "X_valid_pad = sequence.pad_sequences(X_valid_seq, maxlen=max_len, padding='pre')\n",
        "X_test_pad = sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='pre')\n",
        "\n",
        "# Obtain a dictionary mapping unique words in the dataset to numerical indices.\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hh1JEUDh4K7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, Activation, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwYUKgIar1eg"
      },
      "source": [
        "## **Simple RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffSAx9gGhpiR",
        "outputId": "90674115-0c56-412c-f469-77a0e9ff05e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 30, 300)           6903900   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 50)                17550     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6921501 (26.40 MB)\n",
            "Trainable params: 6921501 (26.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "RNN_model = Sequential()\n",
        "RNN_model.add(Embedding(len(word_index) + 1,\n",
        "                        300,\n",
        "                        input_length=max_len))\n",
        "RNN_model.add(SimpleRNN(50))\n",
        "RNN_model.add(Dense(1, activation='sigmoid'))\n",
        "RNN_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "RNN_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajl3h4vrl9Bx"
      },
      "source": [
        "The Sequential model is defined as a sequence of layers to be used in the model. The first layer is the Embedding layer, which converts the one-hot vector representation of words into a 300-dimensional embedding vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqSHDJNIjXGp",
        "outputId": "da0c53d4-9399-44d6-ee9f-cb26acf91f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 27s 58ms/step - loss: 0.1429 - accuracy: 0.9432 - val_loss: 0.0644 - val_accuracy: 0.9784\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 11s 27ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.0608 - val_accuracy: 0.9809\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 11s 27ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0866 - val_accuracy: 0.9734\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 9s 22ms/step - loss: 9.9507e-04 - accuracy: 0.9998 - val_loss: 0.0873 - val_accuracy: 0.9766\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 10s 26ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0781 - val_accuracy: 0.9803\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7defb20d4f10>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RNN_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_valid_pad, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09t6U-WYr4P0"
      },
      "source": [
        "**Model Comment**\n",
        "\n",
        "This model may be experiencing overfitting as evidenced by a training accuracy of 1 while the validation accuracy does not improve, and the validation loss continues to rise while the training loss keeps decreasing.\n",
        "\n",
        "To address this, adjusting hyperparameters, especially the number of neurons in the SimpleRNN layer, may be beneficial. The model might be too complex for this dataset. Additionally, introducing batch normalization and fine-tuning dropout could enhance model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf9et-Fak51P",
        "outputId": "e7eb6362-f6ed-4681-a072-7f8680566633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = RNN_model.predict(X_test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXbr6e4TpoLZ",
        "outputId": "ae6bba4d-6489-4abe-94ac-c59a6fa51b70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "y_pred_binary = y_pred_binary.flatten()\n",
        "y_pred_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNUnqe4Sq0EH",
        "outputId": "837fe6bb-e0e3-463a-83e6-3cf1fa27f1f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_binary = y_test.values\n",
        "y_test_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlERYJJArChp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt4e9sZRrTJo"
      },
      "outputs": [],
      "source": [
        "# Calculating metrics\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "precision = precision_score(y_test_binary, y_pred_binary)\n",
        "recall = recall_score(y_test_binary, y_pred_binary)\n",
        "f1 = f1_score(y_test_binary, y_pred_binary)\n",
        "roc_auc = roc_auc_score(y_test_binary, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go_-LPlwrqiB",
        "outputId": "26c5b1b7-5eb3-4136-a58a-47a3ab920efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9721875\n",
            "Precision: 0.9713038053649408\n",
            "Recall: 0.973125\n",
            "F1 Score: 0.9722135497970652\n",
            "ROC AUC Score: 0.996615234375\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1554   46]\n",
            " [  43 1557]]\n"
          ]
        }
      ],
      "source": [
        "# Calculating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "# Displaying results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfoQhA2ltM4s"
      },
      "source": [
        "## **LSTM's**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "110ygizFtSaR"
      },
      "source": [
        "Because tokenization and padding have already been performed on the text, there is no need to do it again for LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u37wjlDwD5OT"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4LLhu5hutVE"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, embedding_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31kU77eGvraR",
        "outputId": "f8fa40f9-ff58-4a2d-f52f-dd11dd7245c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23013, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrsXrcwatbw5",
        "outputId": "1fecf4fc-79bd-4cfb-a6bf-6e333d51caca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 30, 300)           6903900   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                70200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6974151 (26.60 MB)\n",
            "Trainable params: 70251 (274.42 KB)\n",
            "Non-trainable params: 6903900 (26.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(len(word_index) + 1,\n",
        "                         300,\n",
        "                         weights=[embedding_matrix],\n",
        "                         input_length=max_len,\n",
        "                         trainable=False))\n",
        "LSTM_model.add(LSTM(50, dropout=0.3, recurrent_dropout=0.3))\n",
        "LSTM_model.add(Dense(1, activation='sigmoid'))\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "LSTM_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba90kQYIxqDf"
      },
      "source": [
        "Setting trainable=False on the embedding layer means that the weights of that embedding layer will not be updated or adjusted during the model training process. This is done to prevent overfitting and reduce computational load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO0UsOUpvwad",
        "outputId": "04280582-e7de-4ece-c6c1-9398e4122cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 33s 58ms/step - loss: 0.5356 - accuracy: 0.7211 - val_loss: 0.3472 - val_accuracy: 0.8462\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 20s 50ms/step - loss: 0.3621 - accuracy: 0.8429 - val_loss: 0.3730 - val_accuracy: 0.8378\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 21s 53ms/step - loss: 0.3163 - accuracy: 0.8646 - val_loss: 0.2658 - val_accuracy: 0.8863\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 21s 52ms/step - loss: 0.2892 - accuracy: 0.8786 - val_loss: 0.2573 - val_accuracy: 0.8872\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 21s 52ms/step - loss: 0.2635 - accuracy: 0.8916 - val_loss: 0.1923 - val_accuracy: 0.9191\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7def38b76920>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LSTM_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_valid_pad, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNJUPYFy-oD"
      },
      "source": [
        "**Model Comment**\n",
        "\n",
        "The model performs well as it consistently improves on the validation data. By the 5th epoch, there is a notable decrease in loss and a continuous increase in accuracy, indicating that the model has room for further development. This can be achieved by adding more epochs, increasing dropout, and adjusting hyperparameters, such as the number of units/neurons in the LSTM layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEJO1MCqwWhN",
        "outputId": "7197b58f-9e4b-4b0c-c311-ef07f89781ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = LSTM_model.predict(X_test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Av3L6dwWhN",
        "outputId": "04d314a9-ec80-44ec-f1db-2ea05adac7da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "y_pred_binary = y_pred_binary.flatten()\n",
        "y_pred_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC07D1M_wWhO",
        "outputId": "cd400db8-4849-4217-f286-813c6c64c7ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_binary = y_test.values\n",
        "y_test_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf6070kRwWhO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9EbdjPUwWhO"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "precision = precision_score(y_test_binary, y_pred_binary)\n",
        "recall = recall_score(y_test_binary, y_pred_binary)\n",
        "f1 = f1_score(y_test_binary, y_pred_binary)\n",
        "roc_auc = roc_auc_score(y_test_binary, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMEY5S-UwWhO",
        "outputId": "ec5f0b20-b081-4b43-e871-d4949a335d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9159375\n",
            "Precision: 0.9530292716133424\n",
            "Recall: 0.875\n",
            "F1 Score: 0.9123492994460737\n",
            "ROC AUC Score: 0.975738671875\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1531   69]\n",
            " [ 200 1400]]\n"
          ]
        }
      ],
      "source": [
        "# Calculating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "# Display results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yiN4qqSxCgR"
      },
      "source": [
        "## **GRU's**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FUtmKzix407"
      },
      "outputs": [],
      "source": [
        "from keras.layers import SpatialDropout1D, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnVIK9XKxKro",
        "outputId": "085e7595-dc04-4615-ad8a-f29df084d185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 30, 300)           6903900   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spati  (None, 30, 300)           0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 300)               541800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 301       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7446001 (28.40 MB)\n",
            "Trainable params: 542101 (2.07 MB)\n",
            "Non-trainable params: 6903900 (26.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "GRU_model = Sequential()\n",
        "GRU_model.add(Embedding(len(word_index) + 1,\n",
        "                        300,\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=max_len,\n",
        "                        trainable=False))\n",
        "GRU_model.add(SpatialDropout1D(0.3))\n",
        "GRU_model.add(GRU(300))\n",
        "GRU_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "GRU_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "GRU_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL41sQF20N9V",
        "outputId": "9abf70ec-3054-44ca-becb-4a34a042dd9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 8s 14ms/step - loss: 0.4536 - accuracy: 0.7787 - val_loss: 0.2511 - val_accuracy: 0.9009\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.2572 - accuracy: 0.8942 - val_loss: 0.2127 - val_accuracy: 0.9122\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.2178 - accuracy: 0.9116 - val_loss: 0.2362 - val_accuracy: 0.9047\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.1840 - accuracy: 0.9259 - val_loss: 0.1626 - val_accuracy: 0.9384\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.1636 - accuracy: 0.9363 - val_loss: 0.1369 - val_accuracy: 0.9516\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7def63975150>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GRU_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_valid_pad, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5ttMUSM2bsF"
      },
      "source": [
        "**Model Comment**\n",
        "\n",
        "The model exhibits good performance as it consistently improves on the validation data. By the 5th epoch, there is a noticeable decrease in loss and a continuous increase in accuracy, suggesting that the model can be further developed. This can be achieved by adding more epochs, increasing dropout, and adjusting hyperparameters, such as the number of units/neurons in the GRU layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C1Ai_A-0E5O",
        "outputId": "acb7c7f9-ee72-480f-9185-be85eed884b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = GRU_model.predict(X_test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmSUEoP20E5U",
        "outputId": "1f8bfa41-7d82-414b-80f7-3488d92c7e70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "y_pred_binary = y_pred_binary.flatten()\n",
        "y_pred_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwKKxwVU0E5U",
        "outputId": "8726cd72-475d-489c-ac4d-ae0165927791"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_binary = y_test.values\n",
        "y_test_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGP2vmph0E5U"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-xxh8A0E5U"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "precision = precision_score(y_test_binary, y_pred_binary)\n",
        "recall = recall_score(y_test_binary, y_pred_binary)\n",
        "f1 = f1_score(y_test_binary, y_pred_binary)\n",
        "roc_auc = roc_auc_score(y_test_binary, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77EX-_Cx0E5V",
        "outputId": "e75288e8-25d5-4b25-c1fc-1a3291ec68da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9425\n",
            "Precision: 0.9481012658227848\n",
            "Recall: 0.93625\n",
            "F1 Score: 0.9421383647798742\n",
            "ROC AUC Score: 0.986199609375\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1518   82]\n",
            " [ 102 1498]]\n"
          ]
        }
      ],
      "source": [
        "# Calculating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "# Display results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfgUKnRE21uN"
      },
      "source": [
        "## **Bi-Directional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvU7xlsD3pN5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzQHpHHc25gn",
        "outputId": "4d25939c-d583-46e9-d7da-1d6ba97b121f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 30, 300)           6903900   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 600)               1442400   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8346901 (31.84 MB)\n",
            "Trainable params: 1443001 (5.50 MB)\n",
            "Non-trainable params: 6903900 (26.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "BDRNN_model = Sequential()\n",
        "BDRNN_model.add(Embedding(len(word_index) + 1,\n",
        "                          300,\n",
        "                          weights=[embedding_matrix],\n",
        "                          input_length=max_len,\n",
        "                          trainable=False))\n",
        "BDRNN_model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
        "\n",
        "BDRNN_model.add(Dense(1,activation='sigmoid'))\n",
        "BDRNN_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "BDRNN_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1fJl-eT3UOB"
      },
      "source": [
        "Regular dropout operates on connections between units within a specific timestep, while recurrent dropout operates on recurrent connections between timesteps. Combining both can help reduce overfitting and improve the generalization of recurrent models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsy3BEkN4AR3",
        "outputId": "483eb061-76d8-4934-b313-8c994e327298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 46s 104ms/step - loss: 0.5421 - accuracy: 0.7112 - val_loss: 0.3605 - val_accuracy: 0.8531\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 40s 99ms/step - loss: 0.3506 - accuracy: 0.8501 - val_loss: 0.3595 - val_accuracy: 0.8300\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 41s 102ms/step - loss: 0.2875 - accuracy: 0.8798 - val_loss: 0.2059 - val_accuracy: 0.9200\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 40s 101ms/step - loss: 0.2539 - accuracy: 0.8963 - val_loss: 0.1916 - val_accuracy: 0.9287\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 40s 101ms/step - loss: 0.2314 - accuracy: 0.9050 - val_loss: 0.2164 - val_accuracy: 0.9050\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7def3dfe9b10>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BDRNN_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_valid_pad, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb77JTVP4AR9",
        "outputId": "82333eb7-5098-478b-a77d-482ee534aaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = GRU_model.predict(X_test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1xQdPdg4AR9",
        "outputId": "b200f0b6-695a-42ef-af7c-bff4369f2f9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "y_pred_binary = y_pred_binary.flatten()\n",
        "y_pred_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er3Qbv6b4AR-",
        "outputId": "d6c28bcb-3bb4-4b64-c753-6407295e3a45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_binary = y_test.values\n",
        "y_test_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV_nMSKk4AR-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_JD9vkL4AR-"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "precision = precision_score(y_test_binary, y_pred_binary)\n",
        "recall = recall_score(y_test_binary, y_pred_binary)\n",
        "f1 = f1_score(y_test_binary, y_pred_binary)\n",
        "roc_auc = roc_auc_score(y_test_binary, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U4M23BF4AR-",
        "outputId": "5aabc4fb-0abc-4af5-a8de-af59fe97d30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9425\n",
            "Precision: 0.9481012658227848\n",
            "Recall: 0.93625\n",
            "F1 Score: 0.9421383647798742\n",
            "ROC AUC Score: 0.986199609375\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1518   82]\n",
            " [ 102 1498]]\n"
          ]
        }
      ],
      "source": [
        "# Calculating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "# Display results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meC6puRC4ubN"
      },
      "source": [
        "## **Transformer & BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qhCrZbL6UWd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import transformers\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-C5KO906iLv"
      },
      "outputs": [],
      "source": [
        "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
        "    \"\"\"\n",
        "    Encoder for encoding the text into sequence of integers for BERT Input\n",
        "    \"\"\"\n",
        "    tokenizer.enable_truncation(max_length=maxlen)\n",
        "    tokenizer.enable_padding(length=maxlen)\n",
        "    all_ids = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
        "        text_chunk = texts[i:i+chunk_size].tolist()\n",
        "        encs = tokenizer.encode_batch(text_chunk)\n",
        "        all_ids.extend([enc.ids for enc in encs])\n",
        "\n",
        "    return np.array(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c26fYrl-7faq",
        "outputId": "6d357ba2-17ed-40de-9a82-34524d7fbb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X_train: (25600,)\n",
            "Shape y_train: (25600,)\n",
            "Shape X_val: (3200,)\n",
            "Shape y_val: (3200,)\n",
            "Shape X_test: (3200,)\n",
            "Shape y_test: (3200,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(df.headline, df.clickbait,\n",
        "                                                    stratify=df.clickbait.values,\n",
        "                                                    random_state = 42,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp,\n",
        "                                                stratify=y_temp.values,\n",
        "                                                random_state = 42,\n",
        "                                                test_size = 0.5,\n",
        "                                                shuffle=True)\n",
        "\n",
        "print(\"Shape X_train:\", X_train.shape)\n",
        "print(\"Shape y_train:\", y_train.shape)\n",
        "print(\"Shape X_val:\", X_val.shape)\n",
        "print(\"Shape y_val:\", y_val.shape)\n",
        "print(\"Shape X_test:\", X_test.shape)\n",
        "print(\"Shape y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyuHsw7l6rsn"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lC6DPU-6m5V",
        "outputId": "fdd6b476-968f-4b2b-ca47-d316d875460b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=30522, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=False, wordpieces_prefix=##)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First load the real tokenizer\n",
        "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "# Save the loaded tokenizer locally\n",
        "tokenizer.save_pretrained('.')\n",
        "# Reload it with the huggingface tokenizers library\n",
        "fast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\n",
        "fast_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US8_G4E8_FnL"
      },
      "outputs": [],
      "source": [
        "#IMP DATA FOR CONFIG\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        "# Configuration\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "MAX_LEN = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daBrTxND7QXh",
        "outputId": "945a2f46-1637-4d73-84e6-4f89727c6519"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 102.23it/s]\n",
            "100%|██████████| 13/13 [00:00<00:00, 101.90it/s]\n",
            "100%|██████████| 13/13 [00:00<00:00, 97.89it/s]\n"
          ]
        }
      ],
      "source": [
        "# Using fast_encode on text data\n",
        "X_train_encoded = fast_encode(X_train.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
        "X_val_encoded = fast_encode(X_val.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
        "X_test_encoded = fast_encode(X_test.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
        "\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "y_val = y_val.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J0RWreS8kdw"
      },
      "outputs": [],
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_train_encoded, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_val_encoded, y_val))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(X_test_encoded)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dGDH8j38wqc"
      },
      "outputs": [],
      "source": [
        "def build_model(transformer, max_len=512):\n",
        "    \"\"\"\n",
        "    function for training the BERT model\n",
        "    \"\"\"\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(cls_token)\n",
        "\n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giN3vBTP9Jv3",
        "outputId": "ded3d939-8e9c-46b6-9fa1-f6b8a44ca733"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_word_ids (InputLayer  [(None, 30)]              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf_distil_bert_model_4 (TF  TFBaseModelOutput(last_   66362880  \n",
            " DistilBertModel)            hidden_state=(None, 30,             \n",
            "                              768),                              \n",
            "                              hidden_states=None, at             \n",
            "                             tentions=None)                      \n",
            "                                                                 \n",
            " tf.__operators__.getitem_4  (None, 768)               0         \n",
            "  (SlicingOpLambda)                                              \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 769       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66363649 (253.16 MB)\n",
            "Trainable params: 66363649 (253.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer_layer = (\n",
        "    transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        ")\n",
        "model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OFhCJwA9cSU",
        "outputId": "86ee33ad-df48-4457-8c58-bf83d397eadc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "400/400 [==============================] - 107s 218ms/step - loss: 0.7319 - accuracy: 0.5045 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
            "Epoch 2/3\n",
            "400/400 [==============================] - 85s 212ms/step - loss: 0.6994 - accuracy: 0.4989 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 3/3\n",
            "400/400 [==============================] - 84s 209ms/step - loss: 0.6979 - accuracy: 0.4985 - val_loss: 0.6942 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "n_steps = X_train_encoded.shape[0] // BATCH_SIZE\n",
        "train_history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J8J_r9o9kX_",
        "outputId": "a0636b93-1735-4fb4-bf08-d4b12fb99f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.6936 - accuracy: 0.5106\n",
            "Epoch 2/6\n",
            "50/50 [==============================] - 10s 199ms/step - loss: 0.6948 - accuracy: 0.5013\n",
            "Epoch 3/6\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.6953 - accuracy: 0.4934\n",
            "Epoch 4/6\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.6951 - accuracy: 0.4884\n",
            "Epoch 5/6\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.6951 - accuracy: 0.4903\n",
            "Epoch 6/6\n",
            "50/50 [==============================] - 10s 199ms/step - loss: 0.6950 - accuracy: 0.5025\n"
          ]
        }
      ],
      "source": [
        "n_steps = X_val_encoded.shape[0] // BATCH_SIZE\n",
        "train_history_2 = model.fit(\n",
        "    valid_dataset.repeat(),\n",
        "    steps_per_epoch=n_steps,\n",
        "    epochs=EPOCHS*2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooZUY6gf9mB2",
        "outputId": "482d7a0e-c7ab-4847-9bab-be1565b7d69b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 5s 68ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(test_dataset, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ZEPy0ZIQ2T",
        "outputId": "d7e98d35-8f08-4888-e3c8-3410ad38abd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.45395052, 0.45395052, 0.45395052, ..., 0.45395052, 0.45395052,\n",
              "       0.45395052], dtype=float32)"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpYicRYaI1y5",
        "outputId": "06483293-e1eb-45df-e742-7d2ede4bdf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nilai Unik dalam Array: [0.45395052]\n"
          ]
        }
      ],
      "source": [
        "# Getting unique values\n",
        "unique_values = np.unique(y_pred)\n",
        "\n",
        "print(\"Unique Values in the Array:\", unique_values)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
